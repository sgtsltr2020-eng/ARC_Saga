# ADR-003: PostgreSQL Migration Path (Design Only)

**Status:** Proposed (Design Phase)  
**Date:** 2025-12-05  
**Deciders:** ARC SAGA Architecture Team  
**Context:** SQLite is sufficient for Phase 2.4, but PostgreSQL will be required for multi-user/cloud scaling in Phase 3+.

## Decision

PostgreSQL migration is **designed but not implemented** in Phase 2.4. Migration can be executed when:

- Multi-user concurrent access is required
- Cloud deployment is initiated
- Read replicas for performance are needed

## Design Principles

1. **Zero-Downtime Migration**: Use dual-write pattern (SQLite + PostgreSQL) during transition.
2. **Schema Compatibility**: PostgreSQL schema matches SQLite structure (JSONB for metadata/tags).
3. **Protocol Abstraction**: `StorageBackend` interface already abstracts implementation details.
4. **Connection Pooling**: PostgreSQL backend uses asyncpg with connection pool (min: 5, max: 20).

## Migration Steps (Future Implementation)

### Step 1: Add PostgreSQL Storage Backend

Create `arc_saga/storage/postgresql.py` implementing `StorageBackend`:

```python
class PostgreSQLStorage(StorageBackend):
    async def initialize(self) -> None:
        # Create tables, indexes, FTS indexes
        # Use JSONB for metadata/tags (compatible with SQLite JSON)

    async def save_message(self, message: Message) -> str:
        # Use parameterized queries, RETURNING id
```

### Step 2: Dual-Write Period

Deploy with both SQLite and PostgreSQL:

```python
# Write to both during migration
await sqlite_storage.save_message(msg)
await postgres_storage.save_message(msg)  # Async, non-blocking
```

### Step 3: Data Migration Script

Batch migrate existing SQLite data:

```python
async def migrate_sqlite_to_postgres():
    messages = await sqlite_storage.get_all_messages()
    for batch in chunks(messages, 1000):
        await postgres_storage.bulk_save(batch)
```

### Step 4: Read Migration

Switch reads to PostgreSQL, keep SQLite as backup:

```python
storage = PostgreSQLStorage(primary=True)
fallback_storage = SQLiteStorage()  # Read-only fallback
```

### Step 5: Complete Migration

Remove SQLite writes, archive SQLite file.

## Schema Design

PostgreSQL schema mirrors SQLite with enhancements:

```sql
CREATE TABLE messages (
    id TEXT PRIMARY KEY,
    provider TEXT NOT NULL,
    role TEXT NOT NULL,
    content TEXT NOT NULL,
    tags JSONB DEFAULT '[]'::jsonb,
    timestamp TIMESTAMPTZ NOT NULL,
    metadata JSONB DEFAULT '{}'::jsonb,
    session_id TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- GIN index for JSONB tags/metadata
CREATE INDEX idx_messages_tags ON messages USING GIN (tags);
CREATE INDEX idx_messages_metadata ON messages USING GIN (metadata);

-- Full-text search (PostgreSQL native)
CREATE INDEX idx_messages_content_fts ON messages USING GIN (to_tsvector('english', content));
```

## Consequences

**Positive:**

- Multi-user concurrent access
- Horizontal scaling via read replicas
- Advanced PostgreSQL features (JSONB queries, full-text search)

**Negative:**

- Infrastructure complexity (PostgreSQL server required)
- Connection pool management
- Migration effort (estimated 2-3 days)

**Mitigations:**

- Protocol abstraction minimizes code changes
- Migration script automates data transfer
- Dual-write ensures zero data loss

## References

- SQLite â†’ PostgreSQL migration guide: https://www.postgresql.org/docs/current/app-pgdump.html
- AsyncPG documentation: https://magicstack.github.io/asyncpg/
- StorageBackend protocol: `arc_saga/storage/base.py`
